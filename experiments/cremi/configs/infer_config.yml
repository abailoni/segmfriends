# This config should be combined for example with "example_train_affs_dowscaled_data.yml"

shortcuts:
  z_size: &z_size 12
  xy_size: &xy_size 272
#  rule of thumb:
#  If Shape of final prediction: torch.Size([1, x, x]) and
#  Input size (1, y, y) then
#  Padding of the dataset should be >= (y-x)/2 if you want to avoid border effects with parts that are not predicted.
#  (Assuming that the output of the model is at the same resolution of the input dataset)
  padding: &dataset_padding [[0,0], [50,50], [50,50]]


loaders:
  infer:
    inference_mode: True
    loader_config:
      # Number of processes to use for loading data. Set to (say) 10 if you wish to
      # use 10 CPU cores, or to 0 if you wish to use the same process for training and
      # data-loading (generally not recommended).
      batch_size: 1
      num_workers: 4
      drop_last: False
      #      pin_memory: False
      shuffle: False

    # Which CREMI sample should be used for inference:
    name: C

    volume_config:
      # Sliding window size
      window_size:
        - *z_size
        - *xy_size
        - *xy_size
      stride: [40, 40, 40] # Not needed anymore, automatically deduced during inference
      data_slice: ':15,:,:'
      padding_mode: "reflect"
      padding:
        A: *dataset_padding
        B: *dataset_padding
        C: *dataset_padding
      path:
        A: '$HCI_HOME/datasets/CREMI/padded_data/sample_A_2x.h5'
        B: '$HCI_HOME/datasets/CREMI/padded_data/sample_B_2x.h5'
        C: '$HCI_HOME/datasets/CREMI/padded_data/sample_C_2x.h5'
      path_in_file: 'volumes/raw'
      dtype: float32

inference:
  # How much I crop the predicted tensor: (local_crop in the output resolution)
  crop_prediction:
    - [2,2]
    - [24,24]
    - [24,24]

  # Make sure to exclude the invalid affinities:
  # your model can return a second output tensor that should be a binary tensor indicating with outputs are valid and
  #  which are not
  return_patch_mask: False

  # Change this if the resolution of the output is different from the input:
  output_dws_fact: [1, 1, 1]

  # Should the predicted patches overlap? If yes, by how much?
  window_overlap: [1, 30, 30]
  blending_kwargs:
    dim: 3

  # If your model outputs more than one tensor, use this parameter to select the wanted one
  # TODO: implement multi-output version of the engine
  index_output: 0

